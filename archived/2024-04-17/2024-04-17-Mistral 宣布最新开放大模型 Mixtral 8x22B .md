---
layout: post
title: "Mistral 宣布最新开放大模型 Mixtral 8x22B "
date: 2024-04-17T16:18:44.000Z
author: Solidot
from: https://www.solidot.org/story?sid=77937
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1713370724000-->
[Mistral 宣布最新开放大模型 Mixtral 8x22B](https://www.solidot.org/story?sid=77937)
------

<div>
法国 AI 创业公司 Mistral 宣布了其最新的开放大模型 Mixtral 8x22B，公布的测试显示它是目前最先进的开放模型。Mistral 称 8x22B 是真正开放的模型，使用 Apache 2.0 许可证，允许任何人不受限制的使用。它是一种稀疏 Mixture-of-Experts (SMoE)模型，有 1410 亿参数，但活跃参数仅为 390 亿，在其规模下提供了无与伦比的成本效率。Mixtral 8x22B 的优点包括：精通英语、法语、意大利语、德语和西班牙语，具有强大的数学和编码能力，原生能函数调用，64K 令牌上下文窗口。<p></p>
</div>
