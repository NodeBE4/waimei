---
layout: post
title: "规模更大的 AI 聊天机器人倾向于更可能胡说八道"
date: 2024-09-26T15:50:18.000Z
author: Solidot
from: https://www.solidot.org/story?sid=79358
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1727365818000-->
[规模更大的 AI 聊天机器人倾向于更可能胡说八道](https://www.solidot.org/story?sid=79358)
------

<div>
根据发表在《自然》期刊上的一项研究，参数规模更大的 AI 聊天机器人倾向于更可能胡说八道。西班牙 Valencian Research Institute for Artificial Intelligence 的研究员分析了大模型的幻觉，观察随着模型参数规模愈来愈大其幻觉或错误是如何变化的。研究团队发现，更大更精调的大模型更精确，但也更不可靠。它们产生的错误答案比例略有增加。原因是更大参数规模的模型倾向于更不可能回避问题，比如说不知道答案或改变话题。研究人员说，结果是大模型尝试回答所有问题，生成了更多正确的答案以及更多错误的答案。大模型愈来愈擅长于伪装成无所不知。用户可能会高估 AI 聊天机器人的能力。研究人员分析了三种模型家族：OpenAI 的 GPT、Meta 的 LLaMA 和 BigScience 的开源模型 BLOOM。<p></p>
</div>
