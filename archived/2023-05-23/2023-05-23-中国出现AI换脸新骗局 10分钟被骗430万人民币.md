---
layout: post
title: "中国出现AI换脸新骗局 10分钟被骗430万人民币"
date: 2023-05-23T01:49:59.924Z
author: 联合早报
from: https://www.zaobao.com/realtime/china/story20230522-1397149
tags: [ 联合早报 ]
comments: True
categories: [ 联合早报 ]
---
<!--NaN-->
[中国出现AI换脸新骗局 10分钟被骗430万人民币](https://www.zaobao.com/realtime/china/story20230522-1397149)
------

<div>
<p>随着人工智能的发展，中国近期出现AI换脸新骗局，福州市一名科技公司老板10分钟被骗走430万元（人民币，下同，约82.28万新元）。</p><p>据平安包头微信号星期六（5月20日）发布的消息，包头市公安局电信网络犯罪侦查局5月8日发布一起使用智能AI技术进行电信诈骗的案件。</p><p>案情显示，福州市某科技公司老板郭先生的好友4月20日突然通过微信视频联系到他。朋友称在外地投标需要430万元保证金，要求借郭先生的公司账户过账。</p><section id="imu"><div id="dfp-ad-imu1"></div></section><p>好友向郭先生要了银行卡号，声称已把钱打到郭先生的账户上，还把银行转账底单的截图通过微信发给郭先生。郭先生出于信任在未核实好友转账截图的情况下，就将430万元转出。10分钟后，郭先生微信告诉好友事已办妥，但好友称并无此事。</p><p>郭先生与好友通电话后才发现，骗子通过AI换脸技术，佯装好友对他实施了诈骗。</p><p>在警方和银行的帮助下，从诈骗账户追回336.84万元被骗资金，包头和福州警方仍在追缴剩余的93.16万元。</p><div id="innity-in-post"></div><div id="dfp-ad-midarticlespecial"></div><p>据每经网报道，AI诈骗目前有声音合成和AI换脸两种形式。声音合成诈骗，骗子会先通过骚扰电话提取某人声音，获取素材后进行声音合成，从而可以用伪造的声音骗过对方。</p><p>AI换脸诈骗，骗子会先分析公众在网上发布的信息筛选目标人群，之后通过AI技术换脸伪装，再通过视频进行信息确认，完成诈骗。</p><div class="cx_paywall_placeholder" id="sph_cdp_40"></div>
</div>
