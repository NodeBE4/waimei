---
layout: post
title: "AI 最大的风险来自控制它的人而不是技术本身"
date: 2023-06-01T08:13:47.000Z
author: Solidot
from: https://www.solidot.org/story?sid=75123
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1685607227000-->
[AI 最大的风险来自控制它的人而不是技术本身](https://www.solidot.org/story?sid=75123)
------

<div>
本周一群 AI 创业公司高管和 AI 研究人员再次联合发表声明，警告 AI 可能给人类带来“灭绝风险”，呼吁将减轻 AI 带来的灭绝风险作为全球优先事项。全球优先事项应该是人类面临的最重要最迫切问题，AI 在 2023 年取得了显著进步，也许增加了未来人类遭到灭绝的概率，但远远达不到需要全球采取行动的地步。在 AI 失控前，更可能发生的是人的失控。至今为止的科技史表明，最大的风险不是技术本身，而是控制技术的人利用技术累积权力和财富。签署最新声明的人就是最可能控制 AI 技术的人，他们提出的干预措施将巩固其权力。我们应该警惕既想从中获利又想获得信任的“盗火者”。AI 失控到消灭人类还不过是遥遥无期的事情，我们面临的一个迫切问题是集中式的 AI 将会加剧不平等，破坏个人和集体的自由。<p></p>
</div>
