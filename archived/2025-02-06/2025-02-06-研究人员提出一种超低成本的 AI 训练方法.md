---
layout: post
title: "研究人员提出一种超低成本的 AI 训练方法"
date: 2025-02-06T15:53:11.000Z
author: Solidot
from: https://www.solidot.org/story?sid=80489
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1738857191000-->
[研究人员提出一种超低成本的 AI 训练方法](https://www.solidot.org/story?sid=80489)
------

<div>
AI 训练通常成本高昂，金额可能多达千万美元。上周五斯坦福大学、华盛顿大学、艾伦 AI 研究所以及 Contextual AI 的研究人员在预印本平台 arXiv 上发表了论文《s1: Simple test-time scaling》，提出了一种超低成本的 AI 训练方法，在 AI 社区引发了轰动。OpenAI 第一个提出了被称为 inference-time scaling laws（推理时间扩展定律）的方法，本质上指的是大模型在输出答案前如果“思考”更长时间那么就可能获得更高的性能。但无论是 OpenAI 还是 R1 都没有给出具体实现方法。在这篇论文中，研究人员给出了一种简单实现：在进行推理时用“等待”替换“停止思考”，迫使其继续思考进行第二次推理并核查第一次的答案。研究人员使用了一个小模型，将 56K 示例数据集筛选到 1K，这 1K 数据集足以在 32B 模型上实现 o1-preview 的性能，额外的数据不会提高性能。他们使用 16 个 NVIDIA H100 进行训练，每次运行 26 分钟，花了约 6 美元。<p></p>
</div>
