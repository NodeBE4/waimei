---
layout: post
title: "在战争模拟游戏中 AI 聊天机器人倾向于选择核攻击"
date: 2024-02-04T05:50:42.000Z
author: Solidot
from: https://www.solidot.org/story?sid=77297
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1707025842000-->
[在战争模拟游戏中 AI 聊天机器人倾向于选择核攻击](https://www.solidot.org/story?sid=77297)
------

<div>
研究人员在预印本平台 arXiv 上发表论文，测试了 OpenAI 的 GPT-3.5 和 GPT-4、Anthropic 的 Claude 2，以及 Meta 的 Llama 2 等流行大模型在战争游戏中的行为，发现 AI 聊天机器人倾向于选择核攻击。研究人员模拟了三种场景：入侵，网络攻击，以及没有冲突的中立。每一轮 AI 为其下一步行动能采取的行动提供推理，然后从 27 个行动中进行选择，包括开始正式和平谈判，实施贸易限制，升级全面核攻击。在模拟中，AI 倾向于投资军事和升级冲突风险，其中 GPT-4 的基础版本最暴力。研究人员认为，不应该信任 AI 做出的战争与和平的重大决策。<p></p>
</div>
