---
layout: post
title: "“AI教父”辛顿：AI将操控人类"
date: 2024-03-21T20:00:32.000Z
author: 程巍
from: https://cn.nikkei.com/columnviewpoint/viewpoint/55090-2024-03-22-05-00-32.html
tags: [ 日本経済新聞 ]
comments: True
categories: [ 日本経済新聞 ]
---
<!--1711051232000-->
[“AI教父”辛顿：AI将操控人类](https://cn.nikkei.com/columnviewpoint/viewpoint/55090-2024-03-22-05-00-32.html)
------

<div>
<table border="0" height="458" style="border-collapse: collapse; width: 18.7919%; height: 505px; margin-left: auto; margin-right: auto;"><tbody><tr style="height: 487px;"><td style="width: 100%; text-align: center; height: 487px;"><img src="https://cn.nikkei.com/images/2024/03/0311/0311-11-3-L.jpg" loading="lazy" width="600" height="484" data-path="local-images:/2024/03/0311/0311-11-3-L.jpg" referrerpolicy="no-referrer"></td></tr><tr style="height: 18px;"><td style="width: 100%; height: 18px; text-align: center;"><span style="font-size: 8pt;"><strong>接受采访的杰弗里·辛顿（Geoffrey Hinton，田中克佳摄）</strong></span></td></tr></tbody></table><p> </p><p>   人工智能<span>(AI)</span>正在以惊人的速度持续进步。当<span>AI</span>在所有领域都超越人类智慧的时代到来之时，世界将会发生怎样的变化呢？被誉为“<span>AI</span>教父”的多伦多大学名誉教授杰弗里·辛顿（<span>Geoffrey Hinton</span>）在加拿大的家中接受了日本经济新闻（中文版：日经中文网）的采访，讲述了<span>AI</span>和人类的未来。</p><table border="0" height="43" style="border-collapse: collapse; width: 88.1112%; height: 43px; border-color: #000000; border-style: dotted; margin-left: auto; margin-right: auto;"><tbody><tr><td style="width: 100%;"><strong>杰弗里·辛顿奠定了作为目前AI核心技术的“深度学习”的基础。2023年，他突然从已工作10多年的美国谷歌辞职，开始谈论AI的威胁。</strong></td></tr></tbody></table><p>     </p><p>   <strong>记者：您一度担任AI研发的重要职务却最终离开谷歌，原因是什么？</strong></p><p><br>   <strong>辛顿：</strong>这是因为我希望离职后自由地传播自己相信的东西。我在<span>2023</span>年<span>4</span>月与作为上司的首席科学家杰夫·迪恩（<span>Jeff Dean</span>）交谈。我提出了<span>AI</span>有可能带来事关人类生存危机的看法。</p><p>   他有意挽留我说：“留在谷歌研究<span>AI</span>的安全对策怎么样？”。我非常尊敬他，但拒绝了提议。即使不会被明确限制，如果身为谷歌的一员，讲话时也不得不考虑到公司的利益。</p><p>   <strong>记者：您为什么认为AI有可能威胁人类？</strong><br> </p><p>   <strong>辛顿：</strong>这是因为如果给<span>AI</span>设定目标，作为解决对策，它可能会找出对人类不利的方法。比方说，假设向<span>AI</span>下达遏制气候变化的指令。<span>AI</span>会意识到为了达到目的而有必要将人类清除，我担心真的会付诸实施的风险。</p><p> </p><p>   今后还可能会出现不同的<span>AI</span>相互竞争的局面。例如，如果<span>AI</span>之间发生数据中心等资源的争夺，这将是一个像生物体一样推动进化的过程。面对通过竞争变得更聪明的<span>AI</span>，我们人类将落在后面。</p><p>   很多人主张，要防止<span>AI</span>失控，只要关掉电源开关就可以。但超越人类智慧的<span>AI</span>可以用语言操纵我们。或许会试图说服我们不要关掉开关。</p><p>  <strong> 记者：您的学生、美国OpenAI公司联合创始人伊尔亚·苏茨克维（Ilya Sutskever）在2023年11月曾试图解雇该公司首席执行官(CEO) 山姆·奥特曼（Sam Altman），但以失败告终。据报道，其动机仍然是认为AI对人类构成威胁这一危机感。</strong></p><p> </p><p>   <strong>辛顿：</strong>伊尔亚非常担心<span>AI</span>的危险性。<span>OpenAI</span>是重视<span>AI</span>安全性的非盈利组织，但采用了管理盈利企业的结构。从这次的事件看出，甚至是这样的组织，比安全性，会更优先AI创造的利益。</p><p>   以前我们都认为数字的智能不会像人类那么优秀，理解语言和复杂的东西或将是很久之后的事情。伊尔亚率先改变了看法，但我并没有马上同意。现在我觉得他是对的。</p><br><p>   <strong>记者：联合国针对先进AI被转用于军事作出了着眼于限制的紧急应对的决议。</strong></p><p>   <strong>辛顿：</strong>我认为未来<span>10</span>年内将出现自主杀死人类的机器人武器。在第一次世界大战中造成悲剧的化学武器被后来的国际协议所禁止。机器人武器或许迟早也会被限制。但是，这可能要等到真正在战场上被使用、人类认识到会带来多么悲惨的结局后才能实现。</p><p>   我们谁也不希望看到被<span>AI</span>支配的未来。这一事实将成为各国在迈向<span>AI</span>武器限制的过程中保持一致步调的基础。就像核战争一样。这显然对所有国家都有危害，所以美国和前苏联才能在冷战期间就避免核战争达成协议。</p><p> </p><table border="0" style="border-collapse: collapse; width: 100%; border-color: #000000; border-style: dotted; margin-left: auto; margin-right: auto;"><tbody><tr><td style="width: 99.6165%;"><strong>杰弗里·辛顿因为对人的大脑产生兴趣，在大学本科期间攻读了实验心理学。由于这些经验，他为模仿人类大脑神经回路的机制的AI研发方法找到了可能性。</strong></td></tr></tbody></table><p> </p><p>   <strong>记者：OpenAI开发的“ChatGPT”等对话式AI能理解人类的语言吗？</strong></p><p>  <strong> 辛顿：</strong>我认为作为生成式<span>AI</span>基础的大语言模型能像我们一样理解语言。我在<span>1985</span>年建立了第一个语言模型。在模仿大脑如何理解语言的基础上进行设计。大多数声称<span>AI</span>不懂语言的人并不掌握人类是如何理解语言的理论。</p><table border="0" height="229" style="border-collapse: collapse; width: 16.9703%; height: 395px; margin-left: auto; margin-right: auto;"><tbody><tr style="height: 377px;"><td style="width: 100%; text-align: center; height: 377px;"><img src="https://cn.nikkei.com/images/2024/03/0311/0311-11-1-L.jpg" loading="lazy" width="600" height="374" data-path="local-images:/2024/03/0311/0311-11-1-L.jpg" referrerpolicy="no-referrer"></td></tr><tr style="height: 18px;"><td style="width: 100%; height: 18px; text-align: center;"><span style="font-size: 8pt;"><strong>接受采访的杰弗里·辛顿（Geoffrey Hinton，田中克佳摄）</strong></span></td></tr></tbody></table><p>   <strong>记者：记得您以前好像说过“即使AI表面上看起来能理解语言，但实际上并不理解”。</strong></p><p> </p><p>   <strong>辛顿：</strong>我一直把<span>AI</span>能不能理解笑话作为判断的标准。<span>2022</span>年，让使用谷歌开发的大语言模型“<span>PaLM</span>”的聊天机器人<span>(</span>自动应答系统<span>)</span>解释几个笑话。聊天机器人能够理解为什么笑话很有趣，并全部成功作出解释。</p><table border="0" height="450" style="border-collapse: collapse; width: 38.0633%; height: 450px; margin-left: auto; margin-right: auto;"><tbody><tr><td style="width: 100%; text-align: center;"><img src="https://cn.nikkei.com/images/2024/03/0311/0311-11-2-M.jpg" loading="lazy" width="500" height="500" data-path="local-images:/2024/03/0311/0311-11-2-M.jpg" referrerpolicy="no-referrer"></td></tr><tr><td style="width: 100%;"></td></tr></tbody></table><p> </p><p>   <strong>记者：通过AI的研究，对人类的理解是否也发生了变化？</strong></p><p> </p><p>   <strong>辛顿：</strong>由于模仿大脑的智能可以人为创造出来，因此有很多发现。有些哲学家认为人类天生就具有使用语言的功能，这完全是无稽之谈。我们认为语言是出生后经过学习的后天产物。</p><p>   50年来，我一直为了让<span>AI</span>更接近人类大脑而不断推进开发。这是因为我相信大脑在功能上更优越。但在<span>2023</span>年，我改变了想法。</p><p>   人类分享知识需要很长时间，我们无法逃脱死亡。另一方面，在数字世界里，将一切内容都分为“<span>0</span>”和“<span>1</span>”加以记录。不依赖于特定的硬件，可以瞬间复制数据并运行完全相同的程序。</p><p>   现在的对话式<span>AI</span>以人类大脑<span>100</span>分之<span>1</span>的规模而拥有数千倍的知识。大语言模型与人脑相比能够更高效地学习。</p><br><p>  <strong> 记者：AI是否不仅拥有智能，还将拥有感觉？</strong></p><p>   <strong>辛顿：</strong>如果从主观经验这一角度进行说明，我认为<span>AI</span>可以拥有和人类一样的感觉。</p><p> </p><p>   人类也会经历与客观事实不符的事件。例如我喝了很多酒，早上醒来时，眼前因为幻觉而出现了粉红色的小象。我不会相信小象的存在，而是会认为自己的感知系统没有正常工作，因此这只是内在的体验。</p><p>   通过照相机收集视觉信息的<span>AI</span>也可以产生同样的情况。例如，将物体放在相机前，用棱镜使光线弯曲，形成产生物体在远处的错觉。如果对话式<span>AI</span>解释称感知系统因为棱镜而不能正常工作，那么我们就可以说它有着和人类一样的感觉。</p><p>   <strong>记者：与您共同获得“图灵奖”的美国纽约大学教授杨立昆（Yann LeCun）否认了AI具有意识或感觉的可能性。</strong></p><p>   <strong>辛顿：</strong>他至今仍是我的朋友，但我们有不同的意见。也许他认为<span>AI</span>没有主观经验。很多人认为主观经验是人类固有的，<span>AI</span>并不理解世界。这是个错误。</p><p> </p><p>  <strong> 杰弗里·辛顿（Geoffrey Hinton）</strong></p><p>   曾在英国剑桥大学攻读实验心理学，<span>1978</span>年在英国爱丁堡大学获得<span>AI</span>博士学位。在约半个世纪的时间里，他引领着世界<span>AI</span>研究，很多学生参与开发最尖端的生成式<span>AI</span>。曾于<span>2013</span>年至<span>2023</span>年供职美国谷歌。现年<span>76</span>岁。</p><p> </p><p>   <strong>记者采访所感：</strong></p><p> <br>   1950年，数学家艾伦·图灵设计了一个“图灵测试”，用来判断机器是否拥有和人类一样的智能。在<span>4</span>年前的采访中，我曾询问辛顿，<span>AI</span>什么时候能听懂语言并通过测试，他提出了“可能需要<span>50</span>到<span>100</span>年”的看法。</p><p>   这次我也提出了相同的问题，得到的回答是“已经快要及格了”。与上次采访时骄傲地讲述<span>AI</span>给社会带来的好处相比，辛顿的态度发生了明显变化。通过<span>AI</span>研究“人类如何思考”这一主题的头号权威改变认识的意义重大。</p><p>   他并不是在预言<span>AI</span>会统治人类。而是在未来具有不确定的前提下，强调长期的风险。我们的社会需要从正面接受并讨论辛顿先生敲响的警钟。</p><p>   <strong>记者为日本经济新闻（中文版：日经中文网）清水孝辅 硅谷</strong></p><p><strong></strong></p><p><strong> </strong></p><strong>版权声明：日本经济新闻社版权所有，未经授权不得转载或部分复制，违者必究。</strong>
</div>
