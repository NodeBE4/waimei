---
layout: post
title: "1 位大模型或能解决 AI 的能源需求问题"
date: 2024-05-31T15:29:29.000Z
author: Solidot
from: https://www.solidot.org/story?sid=78323
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1717169369000-->
[1 位大模型或能解决 AI 的能源需求问题](https://www.solidot.org/story?sid=78323)
------

<div>
大模型正变得越来越强大，但对计算和电力的需求也越来越大。大模型如果要变得廉价、快速而且环保，它们需要大幅缩小规模，以便于能在类似手机的设备上本地运行。研究人员正致力于寻找方法实现这一目标。类似所有神经网络，大模型是通过修改人工神经元之间的连接强度进行训练，连接强度以数学参数的形式储存。通过减少参数的精度研究人员能压缩网络，这一过程被称为量化，参数的位数能从 16 位减少到 8 或 4 位，研究人员正致力于将其推向极限——以 1 位精度储存参数。有两种压缩网络的通用方法，其一是训练后量化(PTQ)，其二是量化感知训练(QAT)，研究人员更青睐前者。哈工大的车万翔称，PTQ 相对于 QAT 的优点是不需要收集训练数据，不需要重新训练，训练过程更稳定。QAT 的优点则是模型可能更精确，因为量化从一开始就内置在模型中。去年微软亚洲研究院的研究团队创造了第一个 1 位 PTQ 大模型 BBitNet 1.58b，每个参数占大约 1.5 比特内存，有 30 亿参数的 BitNet 在各种语言任务中的表现和相同参数规模的全精度 LLaMA 模型一样出色，但速度是 2.71 倍，用的 GPU 内存少 72%，GPU 能耗低 94%。<p></p>
</div>
