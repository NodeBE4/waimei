---
layout: post
title: "开发者演示对苹果 CSAM 系统的哈希原像攻击"
date: 2021-08-18T14:55:02.000Z
author: Solidot
from: https://www.solidot.org/story?sid=68596
tags: [ Solidot ]
categories: [ Solidot ]
---
<!--1629298502000-->
[开发者演示对苹果 CSAM 系统的哈希原像攻击](https://www.solidot.org/story?sid=68596)
------

<div>
苹果本月早些时候<a href="https://www.solidot.org/story?sid=68472">宣布了</a>一项受争议的决定：它将扫描美国用户 iPhone 手机上的已知儿童色情照片，利用来自 National Center for Missing and Exploited Children (NCMEC)的 CSAM（Child Sexual Abuse Material）图像哈希值去匹配用户手机上的图像哈希，如果发现至少 30 次匹配成功它将会在审核之后报告给相关机构。但苹果使用的算法模型被发现容易制造哈希碰撞（这被称为原像攻击）。开发者<a href="https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX/issues/1">演示</a>制作两个不同图像但它们在 iPhone 上却有着相同的哈希值。这意味着如果攻击者根据已知 CSAM 图像哈希制作一个相同哈希的图像，然后发送给一名无辜用户（要重复 30 次），如果无辜用户启用了 iCloud 同步，那么苹果的系统将会标记这些图像，然后派人去进行审核，而审核者可能会困惑不已。<p><img src="https://img.solidot.org//0/446/liiLIZF8Uh6yM.jpg" height="120" style="display:block"/></p>
</div>
