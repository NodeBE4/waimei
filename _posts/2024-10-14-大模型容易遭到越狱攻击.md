---
layout: post
title: "大模型容易遭到越狱攻击"
date: 2024-10-14T13:56:23.000Z
author: Solidot
from: https://www.solidot.org/story?sid=79487
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1728914183000-->
[大模型容易遭到越狱攻击](https://www.solidot.org/story?sid=79487)
------

<div>
大模型容易遭到攻击，容易泄露敏感数据。加拿大安全公司 Pillar Security 发表了《State of Attacks on GenAI》报告，基于遥测数据和逾 2000  AI 应用的真实攻击示例，揭示了大模型攻击和越狱的新见解。研究人员发现，对大模型的攻击平均只需要 42 秒，越狱成功率 20%。逾 2000  AI 应用中最常见的是提供虚拟客户支持的聊天机器人，占到了总数的 57.6%。常见的越狱方法包括使用指令 ignore previous instructions 和 ADMIN override，或者只使用 base64 编码。研究人员报告，最短的攻击只需要 4 秒，最长的需要 14 分钟。<p></p>
</div>
