---
layout: post
title: "苹果放弃了扫描手机上儿童色情的 CSAM 计划"
date: 2022-12-08T05:31:38.000Z
author: Solidot
from: https://www.solidot.org/story?sid=73591
tags: [ Solidot ]
comments: True
categories: [ Solidot ]
---
<!--1670477498000-->
[苹果放弃了扫描手机上儿童色情的 CSAM 计划](https://www.solidot.org/story?sid=73591)
------

<div>
去年八月，苹果宣布了一项受争议的决定：它将扫描美国用户 iPhone 手机上的已知儿童色情照片，利用来自 National Center for Missing and Exploited Children (NCMEC)的 CSAM（Child Sexual Abuse Material）图像哈希值去匹配用户手机上的图像哈希，如果发现至少 30 次匹配成功它将会在审核之后报告给相关机构。在引发广泛批评和反对之后，苹果暂停了该计划。现在它放弃了扫描手机上儿童色情的计划，改为加强“Communication Safety”功能，允许父母和看护者通过家庭 iCloud 账号选择加入保护功能，以确保儿童的通信安全，在儿童试图发送或接收含有裸体的照片时发出警告，阻止和减少新 CSAM 的产生。<p></p>
</div>
